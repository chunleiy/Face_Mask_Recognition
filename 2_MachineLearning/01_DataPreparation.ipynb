{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae471d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os # file I/O\n",
    "import numpy as np # scientific computing \n",
    "import pandas as pd # data analysis\n",
    "import cv2 # computer vision\n",
    "import gc # garbage collection \n",
    "from tqdm import tqdm # create for loops\n",
    "from glob import glob # define tha path of all images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f7be1",
   "metadata": {},
   "source": [
    "## Step-1 and 2\n",
    "- Collect all data\n",
    "- Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e23d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir('data')\n",
    "images_path = []\n",
    "labels = []\n",
    "for folder in dirs:\n",
    "    path = glob('./data/{}/*.jpg'.format(folder))\n",
    "    label =['{}'.format(folder)]*len(path)\n",
    "    # append\n",
    "    images_path.extend(path)\n",
    "    labels.extend(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c09fcb",
   "metadata": {},
   "source": [
    "## Step-3\n",
    "- Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d0b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = images_path[1]\n",
    "img = cv2.imread(img_path) # read the image via openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b99f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('original',img)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c836fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection\n",
    "# load face detection model\n",
    "face_detection_model = cv2.dnn.readNetFromCaffe('./models/deploy.prototxt.txt',\n",
    "                                                './models/res10_300x300_ssd_iter_140000_fp16.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e5a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection_dnn(img):\n",
    "    # blob from image (rgb mean subraction image)\n",
    "    image = img.copy()\n",
    "    # height and width\n",
    "    h,w = image.shape[:2] \n",
    "    # calculate the blob from image using CV2 and DNN\n",
    "    blob = cv2.dnn.blobFromImage(image, 1, (300, 300), (104, 117, 123), swapRB=True)\n",
    "    # get the detections\n",
    "    face_detection_model.setInput(blob)\n",
    "    detections = face_detection_model.forward()\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2] # confidence score\n",
    "        if confidence > 0.5:\n",
    "                # indexes 3- 7 contain bonunding box info. Normalize by multipling to the height and width array\n",
    "                box = detections[0,0,i,3:7]*np.array([w,h,w,h]) \n",
    "                box = box.astype(int)\n",
    "                #print(box) pt1 & pt2 are the 2 diaganol points of the rectangle\n",
    "                pt1 = (box[0],box[1])\n",
    "                pt2 = (box[2],box[3])\n",
    "                #cv2.rectangle(image,pt1,pt2,(0,255,0),2) # thickness of the bounding box is 2 pixels\n",
    "                roi = image[box[1]:box[3],box[0]:box[2]] # region of interest to get cropped face\n",
    "\n",
    "                return roi     \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75bf5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_roi = face_detection_dnn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3556d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('roi',img_roi)\n",
    "# cv2.imshow('original',img)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72824dc3",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "- Blob from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140761d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(img):\n",
    "    # blob from image (rgb mean subtraction image)\n",
    "    face = face_detection_dnn(img)\n",
    "    if face is not None:\n",
    "\n",
    "        # computing blob from image. (224, 224) is the size of image, (104,117,123) is the mean RGB value\n",
    "        # create a 4-D blob from image\n",
    "        blob = cv2.dnn.blobFromImage(face,1,(224,224),(104,117,123),swapRB=True)\n",
    "        \n",
    "        # reduce dimension of image to 3_D. Transpose the 3-D\n",
    "        blob_squeeze = np.squeeze(blob).T\n",
    "        \n",
    "        # rotate the image 90 degrees clockwise\n",
    "        blob_rotate = cv2.rotate(blob_squeeze,cv2.ROTATE_90_CLOCKWISE)\n",
    "        \n",
    "        # mirror image (flip)\n",
    "        blob_flip = cv2.flip(blob_rotate,1)\n",
    "        \n",
    "        # remove negative values and normalize\n",
    "        img_norm = np.maximum(blob_flip,0)/blob_flip.max()\n",
    "    \n",
    "        return img_norm\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335cf507",
   "metadata": {},
   "source": [
    "### Apply to all images and create a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c010a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing: 10000it [05:10, 32.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#len(images_path)\n",
    "\n",
    "data_img = []\n",
    "label_img = []\n",
    "i = 0\n",
    "\n",
    "# loop path and label at the same time\n",
    "for path, label in tqdm(zip(images_path,labels),desc='preprocessing'):\n",
    "    img = cv2.imread(path)\n",
    "    process_img = datapreprocess(img)\n",
    "    if process_img is not None:\n",
    "        data_img.append(process_img)\n",
    "        label_img.append(label)\n",
    "          \n",
    "    i += 1\n",
    "    if i%100 == 0:\n",
    "        gc.collect() # cleaar temperary MEM every 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205802bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data_img)\n",
    "y = np.array(label_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee6a90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9959, 224, 224, 3), (9959,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of image and the dimensions (100, 100, 3). less than 10000, might be due to faca ont identifiable\n",
    "X.shape, y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09526e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./data/data_preprocess.npz',X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c7c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
